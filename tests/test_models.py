"""
ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸ í†µí•© í…ŒìŠ¤íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë°ì´í„°ì…‹ê³¼ ëª¨ë¸ì˜ í†µí•© ë™ì‘ì„ ê²€ì¦í•©ë‹ˆë‹¤:
1. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
2. ëª¨ë¸ ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸
3. ì†ì‹¤í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € í…ŒìŠ¤íŠ¸
4. ê°„ë‹¨í•œ í›ˆë ¨ ë£¨í”„ í…ŒìŠ¤íŠ¸

Author: AI Assistant
Date: 2024
"""

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import numpy as np
import matplotlib.pyplot as plt
import sys
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.utils.font_utils import setup_korean_font

# í•œê¸€ í°íŠ¸ ì„¤ì •
setup_korean_font()
from typing import Dict, Any, Tuple

# ë¡œì»¬ ëª¨ë“ˆ import
from src.data.dataset import WatermelonDataset, get_basic_transforms, create_stratified_split, create_dataloaders
from src.models.cnn_models import ModelFactory, LossManager, OptimizerManager, print_model_summary


def test_dataset_loading():
    """ë°ì´í„°ì…‹ ë¡œë”© í…ŒìŠ¤íŠ¸"""
    print("ğŸ“Š ë°ì´í„°ì…‹ ë¡œë”© í…ŒìŠ¤íŠ¸")
    print("-" * 40)
    
    try:
        # ê¸°ë³¸ ë³€í™˜ ì„¤ì •
        transforms = get_basic_transforms()
        
        # ë°ì´í„°ì…‹ ìƒì„± (ìƒˆë¡œìš´ ê²½ë¡œ)
        dataset = WatermelonDataset(
            root_dir="data/features/melspectrogram_data",
            transform=transforms['train'],
            normalize_targets=True
        )
        
        print(f"âœ… ë°ì´í„°ì…‹ ë¡œë”© ì„±ê³µ")
        print(f"  - ì´ ì´ë¯¸ì§€ ìˆ˜: {len(dataset)}")
        print(f"  - Brix í†µê³„: {dataset.get_brix_statistics()}")
        
        # ìƒ˜í”Œ ë°ì´í„° í™•ì¸
        sample_image, sample_label = dataset[0]
        print(f"  - ìƒ˜í”Œ ì´ë¯¸ì§€ í¬ê¸°: {sample_image.shape}")
        print(f"  - ìƒ˜í”Œ ë¼ë²¨ íƒ€ì…: {type(sample_label)}, ê°’: {sample_label}")
        
        return dataset
    
    except Exception as e:
        print(f"âŒ ë°ì´í„°ì…‹ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None


def test_data_splitting(dataset: WatermelonDataset):
    """ë°ì´í„° ë¶„í•  í…ŒìŠ¤íŠ¸"""
    print("\nğŸ”€ ë°ì´í„° ë¶„í•  í…ŒìŠ¤íŠ¸")
    print("-" * 40)
    
    try:
        # ë°ì´í„° ë¶„í• 
        train_indices, val_indices, test_indices = create_stratified_split(
            dataset, 
            train_ratio=0.7, 
            val_ratio=0.15, 
            test_ratio=0.15
        )
        
        print(f"âœ… ë°ì´í„° ë¶„í•  ì„±ê³µ")
        print(f"  - í›ˆë ¨ ë°ì´í„°: {len(train_indices)}ê°œ")
        print(f"  - ê²€ì¦ ë°ì´í„°: {len(val_indices)}ê°œ")
        print(f"  - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_indices)}ê°œ")
        
        return train_indices, val_indices, test_indices
    
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¶„í•  ì‹¤íŒ¨: {e}")
        return None, None, None


def test_dataloader_creation(dataset: WatermelonDataset, train_indices, val_indices, test_indices):
    """DataLoader ìƒì„± í…ŒìŠ¤íŠ¸"""
    print("\nğŸ“¦ DataLoader ìƒì„± í…ŒìŠ¤íŠ¸")
    print("-" * 40)
    
    try:
        # ë³€í™˜ ì„¤ì •
        transforms = get_basic_transforms()
        
        # DataLoader ìƒì„±
        dataloaders = create_dataloaders(
            dataset=dataset,
            train_indices=train_indices,
            val_indices=val_indices,
            test_indices=test_indices,
            batch_size=4,  # ì‘ì€ ë°°ì¹˜ í¬ê¸°ë¡œ í…ŒìŠ¤íŠ¸
            num_workers=0,  # ë©€í‹°í”„ë¡œì„¸ì‹± ë¹„í™œì„±í™”
            train_transforms=transforms['train'],
            val_transforms=transforms['val']
        )
        
        print(f"âœ… DataLoader ìƒì„± ì„±ê³µ")
        
        # ê° DataLoader í…ŒìŠ¤íŠ¸
        for split, dataloader in dataloaders.items():
            print(f"  - {split}: {len(dataloader)}ê°œ ë°°ì¹˜")
            
            # ì²« ë²ˆì§¸ ë°°ì¹˜ í…ŒìŠ¤íŠ¸
            try:
                batch_images, batch_labels = next(iter(dataloader))
                print(f"    ë°°ì¹˜ ì´ë¯¸ì§€ í¬ê¸°: {batch_images.shape}")
                print(f"    ë°°ì¹˜ ë¼ë²¨ í¬ê¸°: {batch_labels.shape}")
            except Exception as e:
                print(f"    âŒ ë°°ì¹˜ ë¡œë”© ì‹¤íŒ¨: {e}")
        
        return dataloaders
    
    except Exception as e:
        print(f"âŒ DataLoader ìƒì„± ì‹¤íŒ¨: {e}")
        return None


def test_model_forward_pass(dataloaders: Dict[str, DataLoader]):
    """ëª¨ë¸ ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§  ëª¨ë¸ ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸")
    print("-" * 40)
    
    # í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ë“¤
    models_to_test = [
        {"name": "VGG-16", "type": "vgg16", "kwargs": {"dropout": 0.5, "use_pretrained": False}},
        {"name": "ì»¤ìŠ¤í…€ CNN", "type": "custom_cnn", "kwargs": {"dropout": 0.3, "use_residual": True}}
    ]
    
    test_results = {}
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
    train_dataloader = dataloaders['train']
    test_images, test_labels = next(iter(train_dataloader))
    
    for model_info in models_to_test:
        try:
            print(f"\nğŸ” {model_info['name']} í…ŒìŠ¤íŠ¸")
            
            # ëª¨ë¸ ìƒì„±
            model = ModelFactory.create_model(model_info['type'], **model_info['kwargs'])
            model.eval()
            
            # ìˆœì „íŒŒ
            with torch.no_grad():
                outputs = model(test_images)
            
            print(f"  âœ… ìˆœì „íŒŒ ì„±ê³µ")
            print(f"    ì…ë ¥ í¬ê¸°: {test_images.shape}")
            print(f"    ì¶œë ¥ í¬ê¸°: {outputs.shape}")
            print(f"    ì˜ˆì¸¡ê°’ ë²”ìœ„: {outputs.min().item():.3f} ~ {outputs.max().item():.3f}")
            
            test_results[model_info['name']] = {
                'model': model,
                'success': True,
                'output_shape': outputs.shape
            }
            
        except Exception as e:
            print(f"  âŒ {model_info['name']} ìˆœì „íŒŒ ì‹¤íŒ¨: {e}")
            test_results[model_info['name']] = {
                'model': None,
                'success': False,
                'error': str(e)
            }
    
    return test_results, (test_images, test_labels)


def test_loss_functions_and_optimizers(model_results: Dict, test_data: Tuple):
    """ì†ì‹¤í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € í…ŒìŠ¤íŠ¸"""
    print("\nâš–ï¸ ì†ì‹¤í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € í…ŒìŠ¤íŠ¸")
    print("-" * 40)
    
    test_images, test_labels = test_data
    
    # í…ŒìŠ¤íŠ¸í•  ì†ì‹¤í•¨ìˆ˜ë“¤
    loss_functions = ['mse', 'mae', 'huber', 'rmse']
    optimizers = ['adam', 'adamw', 'sgd']
    
    # ì„±ê³µí•œ ëª¨ë¸ ì¤‘ í•˜ë‚˜ ì„ íƒ
    successful_model = None
    for name, result in model_results.items():
        if result['success']:
            successful_model = result['model']
            model_name = name
            break
    
    if successful_model is None:
        print("âŒ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ”§ {model_name} ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸")
    
    # ì†ì‹¤í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
    print("\nğŸ“‰ ì†ì‹¤í•¨ìˆ˜ í…ŒìŠ¤íŠ¸:")
    for loss_type in loss_functions:
        try:
            loss_fn = LossManager.get_loss_function(loss_type)
            
            # ëª¨ë¸ ì˜ˆì¸¡
            successful_model.eval()
            with torch.no_grad():
                predictions = successful_model(test_images)
            
            # ì†ì‹¤ ê³„ì‚°
            loss = loss_fn(predictions, test_labels.unsqueeze(1))
            print(f"  âœ… {loss_type.upper()}: {loss.item():.4f}")
            
        except Exception as e:
            print(f"  âŒ {loss_type.upper()} ì‹¤íŒ¨: {e}")
    
    # ì˜µí‹°ë§ˆì´ì € í…ŒìŠ¤íŠ¸
    print("\nğŸ”§ ì˜µí‹°ë§ˆì´ì € í…ŒìŠ¤íŠ¸:")
    for opt_type in optimizers:
        try:
            optimizer = OptimizerManager.get_optimizer(
                successful_model, 
                opt_type, 
                lr=0.001
            )
            print(f"  âœ… {opt_type.upper()}: {optimizer.__class__.__name__}")
            
        except Exception as e:
            print(f"  âŒ {opt_type.upper()} ì‹¤íŒ¨: {e}")


def test_simple_training_loop(dataloaders: Dict[str, DataLoader]):
    """ê°„ë‹¨í•œ í›ˆë ¨ ë£¨í”„ í…ŒìŠ¤íŠ¸"""
    print("\nğŸƒ ê°„ë‹¨í•œ í›ˆë ¨ ë£¨í”„ í…ŒìŠ¤íŠ¸")
    print("-" * 40)
    
    try:
        # ê°„ë‹¨í•œ ëª¨ë¸ ìƒì„±
        model = ModelFactory.create_model('custom_cnn', dropout=0.3, use_residual=False)
        
        # ì†ì‹¤í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €
        criterion = LossManager.get_loss_function('mse')
        optimizer = OptimizerManager.get_optimizer(model, 'adam', lr=0.001)
        
        # í›ˆë ¨ ëª¨ë“œë¡œ ì„¤ì •
        model.train()
        
        # ëª‡ ê°œ ë°°ì¹˜ë¡œ í…ŒìŠ¤íŠ¸
        train_dataloader = dataloaders['train']
        num_test_batches = min(3, len(train_dataloader))
        
        print(f"ğŸ”„ {num_test_batches}ê°œ ë°°ì¹˜ë¡œ í›ˆë ¨ í…ŒìŠ¤íŠ¸")
        
        total_loss = 0.0
        for batch_idx, (images, labels) in enumerate(train_dataloader):
            if batch_idx >= num_test_batches:
                break
            
            # ìˆœì „íŒŒ
            outputs = model(images)
            loss = criterion(outputs, labels.unsqueeze(1))
            
            # ì—­ì „íŒŒ
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            print(f"  ë°°ì¹˜ {batch_idx + 1}: ì†ì‹¤ = {loss.item():.4f}")
        
        avg_loss = total_loss / num_test_batches
        print(f"âœ… í›ˆë ¨ ë£¨í”„ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        print(f"  í‰ê·  ì†ì‹¤: {avg_loss:.4f}")
        
    except Exception as e:
        print(f"âŒ í›ˆë ¨ ë£¨í”„ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")


def run_comprehensive_test():
    """ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸ ì¢…í•© í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # 1. ë°ì´í„°ì…‹ ë¡œë”© í…ŒìŠ¤íŠ¸
    dataset = test_dataset_loading()
    if dataset is None:
        print("âŒ ë°ì´í„°ì…‹ ë¡œë”© ì‹¤íŒ¨ë¡œ í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨")
        return
    
    # 2. ë°ì´í„° ë¶„í•  í…ŒìŠ¤íŠ¸
    train_indices, val_indices, test_indices = test_data_splitting(dataset)
    if train_indices is None:
        print("âŒ ë°ì´í„° ë¶„í•  ì‹¤íŒ¨ë¡œ í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨")
        return
    
    # 3. DataLoader ìƒì„± í…ŒìŠ¤íŠ¸
    dataloaders = test_dataloader_creation(dataset, train_indices, val_indices, test_indices)
    if dataloaders is None:
        print("âŒ DataLoader ìƒì„± ì‹¤íŒ¨ë¡œ í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨")
        return
    
    # 4. ëª¨ë¸ ìˆœì „íŒŒ í…ŒìŠ¤íŠ¸
    model_results, test_data = test_model_forward_pass(dataloaders)
    
    # 5. ì†ì‹¤í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € í…ŒìŠ¤íŠ¸
    test_loss_functions_and_optimizers(model_results, test_data)
    
    # 6. ê°„ë‹¨í•œ í›ˆë ¨ ë£¨í”„ í…ŒìŠ¤íŠ¸
    test_simple_training_loop(dataloaders)
    
    print("\n" + "=" * 50)
    print("ğŸ‰ ì¢…í•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    
    # ê²°ê³¼ ìš”ì•½
    print("\nğŸ“‹ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:")
    successful_models = [name for name, result in model_results.items() if result['success']]
    failed_models = [name for name, result in model_results.items() if not result['success']]
    
    if successful_models:
        print(f"  âœ… ì„±ê³µí•œ ëª¨ë¸: {', '.join(successful_models)}")
    if failed_models:
        print(f"  âŒ ì‹¤íŒ¨í•œ ëª¨ë¸: {', '.join(failed_models)}")
    
    print(f"  ğŸ“Š ë°ì´í„°ì…‹ í¬ê¸°: {len(dataset)}ê°œ ì´ë¯¸ì§€")
    print(f"  ğŸ”€ ë°ì´í„° ë¶„í• : í›ˆë ¨ {len(train_indices)}, ê²€ì¦ {len(val_indices)}, í…ŒìŠ¤íŠ¸ {len(test_indices)}")


if __name__ == "__main__":
    run_comprehensive_test() 