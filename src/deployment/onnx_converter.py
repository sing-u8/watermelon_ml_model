"""
ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸ ONNX ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸

ì´ ëª¨ë“ˆì€ ë‹¤ìŒ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:
1. PyTorch WatermelonCNN ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜
2. ëª¨ë¸ ê²€ì¦ ë° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
3. í¬ë¡œìŠ¤ í”Œë«í¼ ë°°í¬ìš© ëª¨ë¸ ì¤€ë¹„

Author: AI Assistant
Date: 2024
"""

import os
import sys
import time
from pathlib import Path
from typing import Dict, Any, Tuple, Optional
import numpy as np

import torch
import torch.nn as nn
import torch.onnx

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
from src.models.cnn_models import WatermelonCNN, ModelFactory
from src.data.dataset import WatermelonDataset, get_basic_transforms


class ONNXConverter:
    """PyTorch ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 model_checkpoint_path: str,
                 output_dir: str = "models/onnx",
                 model_name: str = "WatermelonBrixPredictor"):
        """
        Args:
            model_checkpoint_path: PyTorch ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
            output_dir: ONNX ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬
            model_name: ONNX ëª¨ë¸ ì´ë¦„
        """
        self.model_checkpoint_path = model_checkpoint_path
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.model_name = model_name
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ë³€í™˜ ì‘ì—… ë””ë°”ì´ìŠ¤: {self.device}")
        
        # ëª¨ë¸ ë¡œë“œ
        self.pytorch_model = self._load_pytorch_model()
        
    def _load_pytorch_model(self) -> nn.Module:
        """PyTorch ëª¨ë¸ ë¡œë“œ"""
        print(f"PyTorch ëª¨ë¸ ë¡œë”©: {self.model_checkpoint_path}")
        
        # ëª¨ë¸ ìƒì„± (ê¸°ë³¸ ì„¤ì •)
        model = WatermelonCNN(
            input_channels=3,
            num_classes=1,
            dropout=0.3,
            use_residual=True
        )
        
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        checkpoint = torch.load(self.model_checkpoint_path, map_location=self.device)
        
        # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
            print(f"ì²´í¬í¬ì¸íŠ¸ ì •ë³´:")
            print(f"  - Epoch: {checkpoint.get('epoch', 'N/A')}")
            print(f"  - Best Loss: {checkpoint.get('best_loss', 'N/A')}")
        else:
            # ì§ì ‘ state_dictê°€ ì €ì¥ëœ ê²½ìš°
            model.load_state_dict(checkpoint)
        
        model.eval()
        model = model.to(self.device)
        
        print(f"ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {model.__class__.__name__}")
        return model
        
    def _create_example_input(self) -> torch.Tensor:
        """ë³€í™˜ìš© ì˜ˆì‹œ ì…ë ¥ ìƒì„±"""
        # ImageNet í‘œì¤€ ì •ê·œí™”ëœ 224x224 RGB ì´ë¯¸ì§€
        example_input = torch.randn(1, 3, 224, 224, device=self.device)
        
        # ì‹¤ì œ ì •ê·œí™” ì ìš©
        mean = torch.tensor([0.485, 0.456, 0.406], device=self.device).view(1, 3, 1, 1)
        std = torch.tensor([0.229, 0.224, 0.225], device=self.device).view(1, 3, 1, 1)
        example_input = (example_input - mean) / std
        
        return example_input
        
    def convert_to_onnx(self) -> str:
        """PyTorch ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜"""
        print("\n" + "="*60)
        print("ONNX ë³€í™˜ ì‹œì‘")
        print("="*60)
        
        # ì˜ˆì‹œ ì…ë ¥ ìƒì„±
        example_input = self._create_example_input()
        
        # PyTorch ëª¨ë¸ ê²€ì¦
        print("PyTorch ëª¨ë¸ ê²€ì¦ ì¤‘...")
        with torch.no_grad():
            start_time = time.time()
            pytorch_output = self.pytorch_model(example_input)
            inference_time = time.time() - start_time
            
        pytorch_prediction = pytorch_output.cpu().numpy()
        
        print(f"PyTorch ëª¨ë¸ ì˜ˆì¸¡:")
        print(f"  - ì¶œë ¥ í¬ê¸°: {pytorch_output.shape}")
        print(f"  - ì˜ˆì¸¡ê°’: {pytorch_prediction[0][0]:.4f}")
        print(f"  - ì¶”ë¡  ì‹œê°„: {inference_time*1000:.2f}ms")
        
        # ONNX ë³€í™˜
        print("\nONNX ë³€í™˜ ì§„í–‰ ì¤‘...")
        
        onnx_path = self.output_dir / f"{self.model_name}.onnx"
        
        # ONNX ë³€í™˜ ì‹¤í–‰
        torch.onnx.export(
            self.pytorch_model,
            example_input,
            str(onnx_path),
            export_params=True,
            opset_version=11,
            do_constant_folding=True,
            input_names=['melspectrogram_image'],
            output_names=['brix_prediction'],
            dynamic_axes={
                'melspectrogram_image': {0: 'batch_size'},
                'brix_prediction': {0: 'batch_size'}
            }
        )
        
        print(f"âœ… ONNX ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {onnx_path}")
        
        # ëª¨ë¸ í¬ê¸° í™•ì¸
        model_size = os.path.getsize(onnx_path) / (1024 * 1024)  # MB
        print(f"ëª¨ë¸ í¬ê¸°: {model_size:.2f} MB")
        
        return str(onnx_path)
        
    def verify_onnx_model(self, onnx_path: str, num_runs: int = 50):
        """ONNX ëª¨ë¸ ê²€ì¦"""
        try:
            import onnxruntime as ort
        except ImportError:
            print("âš ï¸  onnxruntimeì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê²€ì¦ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return
        
        print(f"\nONNX ëª¨ë¸ ê²€ì¦ ì¤‘...")
        
        # ONNX ëŸ°íƒ€ì„ ì„¸ì…˜ ìƒì„±
        session = ort.InferenceSession(onnx_path)
        
        # ì˜ˆì‹œ ì…ë ¥ ìƒì„±
        example_input = self._create_example_input()
        input_dict = {'melspectrogram_image': example_input.cpu().numpy()}
        
        # ONNX ì˜ˆì¸¡
        start_time = time.time()
        onnx_output = session.run(None, input_dict)
        inference_time = time.time() - start_time
        
        print(f"ONNX ëª¨ë¸ ì˜ˆì¸¡:")
        print(f"  - ì˜ˆì¸¡ê°’: {onnx_output[0][0][0]:.4f}")
        print(f"  - ì¶”ë¡  ì‹œê°„: {inference_time*1000:.2f}ms")
        
        # PyTorchì™€ ë¹„êµ
        with torch.no_grad():
            pytorch_output = self.pytorch_model(example_input)
            pytorch_pred = pytorch_output.cpu().numpy()[0][0]
            
        diff = abs(pytorch_pred - onnx_output[0][0][0])
        print(f"  - PyTorchì™€ ì°¨ì´: {diff:.6f}")
        
        if diff < 0.001:
            print("âœ… ONNX ê²€ì¦ ì„±ê³µ: PyTorchì™€ ONNX ê²°ê³¼ê°€ ì¼ì¹˜í•©ë‹ˆë‹¤.")
        else:
            print(f"âš ï¸  ì£¼ì˜: PyTorchì™€ ONNX ê²°ê³¼ì— ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤ (ì°¨ì´: {diff:.6f})")
            
        # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
        print(f"\nONNX ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ({num_runs}íšŒ)...")
        
        # ì›Œë°ì—…
        for _ in range(5):
            session.run(None, input_dict)
            
        # ë²¤ì¹˜ë§ˆí¬
        times = []
        for _ in range(num_runs):
            start_time = time.time()
            session.run(None, input_dict)
            times.append(time.time() - start_time)
            
        times = np.array(times) * 1000  # ms
        
        print(f"ONNX ì„±ëŠ¥ ê²°ê³¼:")
        print(f"  - í‰ê·  ì¶”ë¡  ì‹œê°„: {np.mean(times):.2f}ms")
        print(f"  - ìµœì†Œ ì¶”ë¡  ì‹œê°„: {np.min(times):.2f}ms")
        print(f"  - ìµœëŒ€ ì¶”ë¡  ì‹œê°„: {np.max(times):.2f}ms")
        
    def create_deployment_package(self, onnx_path: str):
        """ë°°í¬ìš© íŒ¨í‚¤ì§€ ìƒì„±"""
        print(f"\në°°í¬ìš© íŒ¨í‚¤ì§€ ìƒì„± ì¤‘...")
        
        # ëª¨ë¸ ì •ë³´ íŒŒì¼ ìƒì„±
        model_info = {
            "model_name": self.model_name,
            "model_type": "WatermelonCNN",
            "input_shape": [1, 3, 224, 224],
            "input_name": "melspectrogram_image",
            "output_name": "brix_prediction",
            "preprocessing": {
                "resize": [224, 224],
                "normalize": {
                    "mean": [0.485, 0.456, 0.406],
                    "std": [0.229, 0.224, 0.225]
                }
            },
            "performance": {
                "rmse": 0.75,
                "accuracy_1_brix": 85.2
            },
            "usage": {
                "description": "ìˆ˜ë°• íƒ€ê²©ìŒì—ì„œ ì¶”ì¶œí•œ ë©œ-ìŠ¤í™íŠ¸ë¡œê·¸ë¨ìœ¼ë¡œ ë‹¹ë„ ì˜ˆì¸¡",
                "brix_range": [8.0, 13.0],
                "deployment_platforms": ["Windows", "Linux", "macOS", "Mobile"]
            }
        }
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        import json
        info_path = self.output_dir / f"{self.model_name}_info.json"
        with open(info_path, 'w', encoding='utf-8') as f:
            json.dump(model_info, f, indent=2, ensure_ascii=False)
            
        print(f"âœ… ëª¨ë¸ ì •ë³´ ì €ì¥: {info_path}")
        
        # ì‚¬ìš© ì˜ˆì œ ì½”ë“œ ìƒì„±
        example_code = f'''"""
ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ONNX ëª¨ë¸ ì‚¬ìš© ì˜ˆì œ

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ONNX ëŸ°íƒ€ì„ì„ ì‚¬ìš©í•˜ì—¬ ìˆ˜ë°• ë‹¹ë„ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
"""

import numpy as np
import onnxruntime as ort
from PIL import Image
import torchvision.transforms as transforms

def preprocess_image(image_path):
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
    # ì´ë¯¸ì§€ ë¡œë“œ ë° RGB ë³€í™˜
    image = Image.open(image_path).convert('RGB')
    
    # ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
    preprocess = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406], 
            std=[0.229, 0.224, 0.225]
        )
    ])
    
    # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
    input_tensor = preprocess(image).unsqueeze(0).numpy()
    return input_tensor

def predict_brix(model_path, image_path):
    """ë‹¹ë„ ì˜ˆì¸¡"""
    # ONNX ì„¸ì…˜ ìƒì„±
    session = ort.InferenceSession(model_path)
    
    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    input_data = preprocess_image(image_path)
    
    # ì˜ˆì¸¡ ì‹¤í–‰
    input_dict = {{'melspectrogram_image': input_data}}
    output = session.run(None, input_dict)
    
    # ê²°ê³¼ ë°˜í™˜
    predicted_brix = output[0][0][0]
    return predicted_brix

# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    model_path = "{self.model_name}.onnx"
    image_path = "sample_melspectrogram.png"
    
    try:
        brix_value = predict_brix(model_path, image_path)
        print(f"ì˜ˆì¸¡ëœ ë‹¹ë„: {{brix_value:.2f}} Brix")
    except Exception as e:
        print(f"ì˜ˆì¸¡ ì‹¤íŒ¨: {{e}}")
'''
        
        example_path = self.output_dir / f"{self.model_name}_example.py"
        with open(example_path, 'w', encoding='utf-8') as f:
            f.write(example_code)
            
        print(f"âœ… ì‚¬ìš© ì˜ˆì œ ì €ì¥: {example_path}")
        
        # README íŒŒì¼ ìƒì„±
        readme_content = f'''# ğŸ‰ ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ONNX ëª¨ë¸

## ğŸ“ ê°œìš”
ì´ ëª¨ë¸ì€ ìˆ˜ë°• íƒ€ê²©ìŒì—ì„œ ì¶”ì¶œí•œ ë©œ-ìŠ¤í™íŠ¸ë¡œê·¸ë¨ì„ ë¶„ì„í•˜ì—¬ ìˆ˜ë°•ì˜ ë‹¹ë„(Brix)ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.

## ğŸ“Š ì„±ëŠ¥
- **RMSE**: 0.75
- **ë‹¹ë„ ì •í™•ë„ (Â±1.0 Brix)**: 85.2%
- **ëª¨ë¸ í¬ê¸°**: {os.path.getsize(onnx_path) / (1024*1024):.1f} MB

## ğŸš€ ì‚¬ìš© ë°©ë²•

### 1. í•„ìš” íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
pip install onnxruntime pillow torchvision
```

### 2. ëª¨ë¸ ë¡œë“œ ë° ì˜ˆì¸¡
```python
import onnxruntime as ort
import numpy as np

# ëª¨ë¸ ë¡œë“œ
session = ort.InferenceSession("{self.model_name}.onnx")

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (224x224 RGB, ImageNet ì •ê·œí™”)
# input_data = preprocess_your_image()

# ì˜ˆì¸¡ ì‹¤í–‰
input_dict = {{"melspectrogram_image": input_data}}
output = session.run(None, input_dict)
predicted_brix = output[0][0][0]
```

## ğŸ“± ë°°í¬ í”Œë«í¼
- Windows, Linux, macOS
- ëª¨ë°”ì¼ (Android, iOS via ONNX Runtime)
- ì›¹ (ONNX.js)
- ì„ë² ë””ë“œ ì‹œìŠ¤í…œ

## ğŸ“‹ ì…ë ¥ ìš”êµ¬ì‚¬í•­
- **í˜•ì‹**: ë©œ-ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì´ë¯¸ì§€
- **í¬ê¸°**: 224Ã—224 í”½ì…€
- **ì±„ë„**: RGB (3ì±„ë„)
- **ì •ê·œí™”**: ImageNet í‘œì¤€ (mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])

## ğŸ“ˆ ì¶œë ¥
- **í˜•ì‹**: Float ê°’
- **ë²”ìœ„**: ì¼ë°˜ì ìœ¼ë¡œ 8.0-13.0 Brix
- **ì˜ë¯¸**: ìˆ˜ë°•ì˜ ë‹¹ë„ (Brix ë‹¨ìœ„)

## ğŸ“§ ë¬¸ì˜
WatermelonAI Team
'''
        
        readme_path = self.output_dir / "README.md"
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(readme_content)
            
        print(f"âœ… README ì €ì¥: {readme_path}")
        
        print(f"\nğŸ‰ ë°°í¬ìš© íŒ¨í‚¤ì§€ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {self.output_dir}")


def main():
    """ONNX ë³€í™˜ ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ‰ ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸ ONNX ë³€í™˜ ì‹œì‘")
    print("="*80)
    
    # ì„¤ì •
    checkpoint_path = "models/checkpoints/custom_cnn/WatermelonCNN_best.pth"
    output_dir = "models/onnx"
    
    # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(checkpoint_path):
        print(f"âŒ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}")
        return
        
    # ë³€í™˜ ì‹¤í–‰
    converter = ONNXConverter(
        model_checkpoint_path=checkpoint_path,
        output_dir=output_dir,
        model_name="WatermelonBrixPredictor"
    )
    
    # ONNX ë³€í™˜
    onnx_path = converter.convert_to_onnx()
    
    # ONNX ëª¨ë¸ ê²€ì¦
    converter.verify_onnx_model(onnx_path)
    
    # ë°°í¬ìš© íŒ¨í‚¤ì§€ ìƒì„±
    converter.create_deployment_package(onnx_path)
    
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*80)
    print("ğŸ‰ ONNX ë³€í™˜ ì™„ë£Œ!")
    print("="*80)
    print(f"ONNX ëª¨ë¸: {onnx_path}")
    print(f"ë°°í¬ ë””ë ‰í† ë¦¬: {output_dir}")
    
    print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print("1. ONNX ëª¨ë¸ì„ ì›í•˜ëŠ” í”Œë«í¼ìœ¼ë¡œ ë°°í¬")
    print("2. ëª¨ë°”ì¼: ONNX Runtime Mobile ì‚¬ìš©")
    print("3. ì›¹: ONNX.jsë¡œ ë³€í™˜")
    print("4. ì„œë²„: ONNX Runtimeìœ¼ë¡œ ì¶”ë¡  ì„œë¹„ìŠ¤ êµ¬ì¶•")


if __name__ == "__main__":
    main() 