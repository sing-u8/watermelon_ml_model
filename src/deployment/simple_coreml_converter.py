"""
ê°„ë‹¨í•œ Core ML ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸
PyTorch ëª¨ë¸ì„ Core MLë¡œ ë³€í™˜í•˜ê³  .mlmodel í˜•ì‹ìœ¼ë¡œ ì €ì¥

Author: AI Assistant
Date: 2024
"""

import os
import sys
import torch
import torch.nn as nn
import numpy as np
from pathlib import Path

# Core ML ë³€í™˜ ë„êµ¬
import coremltools as ct

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
from src.models.cnn_models import WatermelonCNN


def load_pytorch_model(checkpoint_path: str) -> nn.Module:
    """PyTorch ëª¨ë¸ ë¡œë“œ"""
    print(f"PyTorch ëª¨ë¸ ë¡œë”©: {checkpoint_path}")
    
    # ëª¨ë¸ ìƒì„±
    model = WatermelonCNN(
        input_channels=3,
        num_classes=1,
        dropout=0.3,
        use_residual=True
    )
    
    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    device = torch.device("cpu")
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
        print(f"ì²´í¬í¬ì¸íŠ¸ ì •ë³´: Epoch {checkpoint.get('epoch', 'N/A')}")
    else:
        model.load_state_dict(checkpoint)
    
    model.eval()
    print("âœ… PyTorch ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
    return model


def convert_to_coreml(pytorch_model: nn.Module) -> ct.models.MLModel:
    """PyTorch ëª¨ë¸ì„ Core MLë¡œ ë³€í™˜"""
    print("\nğŸ”„ Core ML ë³€í™˜ ì‹œì‘...")
    
    # ì˜ˆì‹œ ì…ë ¥ ìƒì„±
    example_input = torch.randn(1, 3, 224, 224)
    
    # PyTorch ëª¨ë¸ í…ŒìŠ¤íŠ¸
    with torch.no_grad():
        pytorch_output = pytorch_model(example_input)
        print(f"PyTorch ì˜ˆì¸¡ê°’: {pytorch_output.item():.4f}")
    
    # TorchScriptë¡œ ë³€í™˜
    print("TorchScript ë³€í™˜ ì¤‘...")
    traced_model = torch.jit.trace(pytorch_model, example_input)
    
    # Core ML ë³€í™˜ (ê°„ë‹¨í•œ ì„¤ì •)
    print("Core ML ë³€í™˜ ì¤‘...")
    try:
        coreml_model = ct.convert(
            traced_model,
            inputs=[ct.TensorType(name="melspectrogram_image", shape=example_input.shape)],
            outputs=[ct.TensorType(name="brix_prediction")],
            convert_to="neuralnetwork",  # í˜¸í™˜ì„±ì„ ìœ„í•´ neuralnetwork í˜•ì‹ ì‚¬ìš©
            minimum_deployment_target=ct.target.iOS13
        )
        print("âœ… Core ML ë³€í™˜ ì„±ê³µ!")
        return coreml_model
        
    except Exception as e:
        print(f"âŒ Core ML ë³€í™˜ ì‹¤íŒ¨: {e}")
        print("ë‹¤ë¥¸ ì„¤ì •ìœ¼ë¡œ ì¬ì‹œë„...")
        
        # ë” ê¸°ë³¸ì ì¸ ì„¤ì •ìœ¼ë¡œ ì¬ì‹œë„
        coreml_model = ct.convert(traced_model)
        print("âœ… ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ Core ML ë³€í™˜ ì„±ê³µ!")
        return coreml_model


def add_metadata(coreml_model: ct.models.MLModel):
    """ë©”íƒ€ë°ì´í„° ì¶”ê°€"""
    print("ë©”íƒ€ë°ì´í„° ì¶”ê°€ ì¤‘...")
    
    coreml_model.short_description = "ìˆ˜ë°• ë‹¹ë„(Brix) ì˜ˆì¸¡ AI ëª¨ë¸"
    coreml_model.author = "WatermelonAI Team"
    coreml_model.license = "MIT License"
    coreml_model.version = "1.0.0"
    
    # ì…ë ¥/ì¶œë ¥ ì„¤ëª…
    spec = coreml_model.get_spec()
    if len(spec.description.input) > 0:
        input_name = spec.description.input[0].name
        coreml_model.input_description[input_name] = (
            "ìˆ˜ë°• íƒ€ê²©ìŒì—ì„œ ì¶”ì¶œí•œ ë©œ-ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì´ë¯¸ì§€ (224x224 RGB). "
            "ImageNet í‘œì¤€ìœ¼ë¡œ ì •ê·œí™”ëœ ìƒíƒœì—¬ì•¼ í•¨."
        )
    
    if len(spec.description.output) > 0:
        output_name = spec.description.output[0].name
        coreml_model.output_description[output_name] = (
            "ì˜ˆì¸¡ëœ ìˆ˜ë°• ë‹¹ë„ ê°’ (Brix). ì¼ë°˜ì ìœ¼ë¡œ 8.0-13.0 ë²”ìœ„ì˜ ê°’ì„ ê°€ì§."
        )
    
    print("âœ… ë©”íƒ€ë°ì´í„° ì¶”ê°€ ì™„ë£Œ")


def save_coreml_model(coreml_model: ct.models.MLModel, output_path: str) -> bool:
    """Core ML ëª¨ë¸ ì €ì¥"""
    print(f"\nğŸ’¾ Core ML ëª¨ë¸ ì €ì¥ ì¤‘: {output_path}")
    
    try:
        # .mlmodel í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ë” í˜¸í™˜ì„±ì´ ì¢‹ìŒ)
        if not output_path.endswith('.mlmodel'):
            output_path = output_path.replace('.mlpackage', '.mlmodel')
        
        coreml_model.save(output_path)
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = Path(output_path).stat().st_size / (1024 * 1024)  # MB
        print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ!")
        print(f"   íŒŒì¼ ê²½ë¡œ: {output_path}")
        print(f"   íŒŒì¼ í¬ê¸°: {file_size:.2f} MB")
        return True
        
    except Exception as e:
        print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # ëŒ€ì•ˆ: ë‹¤ë¥¸ ê²½ë¡œë¡œ ì‹œë„
        try:
            alt_path = output_path.replace('.mlmodel', '_fallback.mlmodel')
            coreml_model.save(alt_path)
            print(f"âœ… ëŒ€ì•ˆ ê²½ë¡œë¡œ ì €ì¥ ì„±ê³µ: {alt_path}")
            return True
        except Exception as e2:
            print(f"âŒ ëŒ€ì•ˆ ì €ì¥ë„ ì‹¤íŒ¨: {e2}")
            return False


def test_coreml_model(coreml_model: ct.models.MLModel):
    """Core ML ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª Core ML ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘...")
    
    try:
        # í…ŒìŠ¤íŠ¸ ì…ë ¥ ìƒì„±
        test_input = np.random.randn(1, 3, 224, 224).astype(np.float32)
        
        # ì…ë ¥ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
        spec = coreml_model.get_spec()
        input_name = spec.description.input[0].name
        
        # ì˜ˆì¸¡ ì‹¤í–‰
        prediction = coreml_model.predict({input_name: test_input})
        pred_value = list(prediction.values())[0]
        
        if isinstance(pred_value, np.ndarray):
            pred_value = pred_value.flatten()[0]
            
        print(f"âœ… Core ML ì˜ˆì¸¡ ì„±ê³µ: {pred_value:.4f} Brix")
        return True
        
    except Exception as e:
        print(f"âš ï¸ Core ML í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ (í™˜ê²½ ë¬¸ì œì¼ ìˆ˜ ìˆìŒ): {e}")
        print("iOS/macOS ê¸°ê¸°ì—ì„œ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”.")
        return False


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ‰ ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸ â†’ Core ML ë³€í™˜")
    print("=" * 50)
    
    # ì„¤ì •
    checkpoint_path = "models/checkpoints/custom_cnn/WatermelonCNN_best.pth"
    output_dir = Path("models/coreml")
    output_dir.mkdir(parents=True, exist_ok=True)
    output_path = output_dir / "WatermelonBrixPredictor.mlmodel"
    
    try:
        # 1. PyTorch ëª¨ë¸ ë¡œë“œ
        pytorch_model = load_pytorch_model(checkpoint_path)
        
        # 2. Core ML ë³€í™˜
        coreml_model = convert_to_coreml(pytorch_model)
        
        # 3. ë©”íƒ€ë°ì´í„° ì¶”ê°€
        add_metadata(coreml_model)
        
        # 4. ëª¨ë¸ ì €ì¥
        if save_coreml_model(coreml_model, str(output_path)):
            # 5. ëª¨ë¸ í…ŒìŠ¤íŠ¸
            test_coreml_model(coreml_model)
            
            print(f"\nğŸ‰ ë³€í™˜ ì™„ë£Œ!")
            print(f"Core ML ëª¨ë¸: {output_path}")
            print(f"\nğŸ“± ì´ì œ Swift í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
            
            # Swift ì‚¬ìš©ë²• ì•ˆë‚´
            print(f"\nğŸ“‹ Swiftì—ì„œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•:")
            print(f"1. {output_path} íŒŒì¼ì„ Xcode í”„ë¡œì íŠ¸ì— ì¶”ê°€")
            print(f"2. import CoreML")
            print(f"3. let model = try! WatermelonBrixPredictor(configuration: MLModelConfiguration())")
            print(f"4. let prediction = try! model.prediction(melspectrogram_image: pixelBuffer)")
            
        else:
            print("âŒ ë³€í™˜ ì‹¤íŒ¨")
            
    except Exception as e:
        print(f"âŒ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 