"""
ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸ Core ML ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸

ì´ ëª¨ë“ˆì€ ë‹¤ìŒ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:
1. PyTorch WatermelonCNN ëª¨ë¸ì„ Core MLë¡œ ë³€í™˜
2. Float16 ì–‘ìí™”ë¥¼ í†µí•œ ëª¨ë¸ ìµœì í™”
3. iOS/macOS ë°°í¬ìš© ë©”íƒ€ë°ì´í„° ì¶”ê°€
4. ë³€í™˜ëœ ëª¨ë¸ ê²€ì¦ ë° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

Author: AI Assistant
Date: 2024
"""

import os
import sys
import time
from pathlib import Path
from typing import Dict, Any, Tuple, Optional
import numpy as np

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import torchvision.transforms as transforms

# Core ML ë³€í™˜ ë„êµ¬
import coremltools as ct
from coremltools.models import MLModel
from coremltools.models.neural_network import quantization_utils

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
from src.models.cnn_models import WatermelonCNN, ModelFactory
from src.data.dataset import WatermelonDataset, get_basic_transforms


class CoreMLConverter:
    """PyTorch ëª¨ë¸ì„ Core MLë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 model_checkpoint_path: str,
                 output_dir: str = "models/coreml",
                 model_name: str = "WatermelonBrixPredictor"):
        """
        Args:
            model_checkpoint_path: PyTorch ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
            output_dir: Core ML ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬
            model_name: Core ML ëª¨ë¸ ì´ë¦„
        """
        self.model_checkpoint_path = model_checkpoint_path
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.model_name = model_name
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ë³€í™˜ ì‘ì—… ë””ë°”ì´ìŠ¤: {self.device}")
        
        # ëª¨ë¸ ë¡œë“œ
        self.pytorch_model = self._load_pytorch_model()
        
    def _load_pytorch_model(self) -> nn.Module:
        """PyTorch ëª¨ë¸ ë¡œë“œ"""
        print(f"PyTorch ëª¨ë¸ ë¡œë”©: {self.model_checkpoint_path}")
        
        # ëª¨ë¸ ìƒì„± (ê¸°ë³¸ ì„¤ì •)
        model = WatermelonCNN(
            input_channels=3,
            num_classes=1,
            dropout=0.3,
            use_residual=True
        )
        
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        checkpoint = torch.load(self.model_checkpoint_path, map_location=self.device)
        
        # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
            print(f"ì²´í¬í¬ì¸íŠ¸ ì •ë³´:")
            print(f"  - Epoch: {checkpoint.get('epoch', 'N/A')}")
            print(f"  - Best Loss: {checkpoint.get('best_loss', 'N/A')}")
        else:
            # ì§ì ‘ state_dictê°€ ì €ì¥ëœ ê²½ìš°
            model.load_state_dict(checkpoint)
        
        model.eval()
        model = model.to(self.device)
        
        print(f"ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {model.__class__.__name__}")
        return model
        
    def _create_example_input(self) -> torch.Tensor:
        """ë³€í™˜ìš© ì˜ˆì‹œ ì…ë ¥ ìƒì„±"""
        # ImageNet í‘œì¤€ ì •ê·œí™”ëœ 224x224 RGB ì´ë¯¸ì§€
        example_input = torch.randn(1, 3, 224, 224, device=self.device)
        
        # ì‹¤ì œ ì •ê·œí™” ì ìš© (ì„ íƒì‚¬í•­)
        mean = torch.tensor([0.485, 0.456, 0.406], device=self.device).view(1, 3, 1, 1)
        std = torch.tensor([0.229, 0.224, 0.225], device=self.device).view(1, 3, 1, 1)
        example_input = (example_input - mean) / std
        
        return example_input
        
    def _verify_pytorch_model(self, example_input: torch.Tensor) -> np.ndarray:
        """PyTorch ëª¨ë¸ ê²€ì¦"""
        print("PyTorch ëª¨ë¸ ê²€ì¦ ì¤‘...")
        
        with torch.no_grad():
            start_time = time.time()
            pytorch_output = self.pytorch_model(example_input)
            inference_time = time.time() - start_time
            
        pytorch_prediction = pytorch_output.cpu().numpy()
        
        print(f"PyTorch ëª¨ë¸ ì˜ˆì¸¡:")
        print(f"  - ì¶œë ¥ í¬ê¸°: {pytorch_output.shape}")
        print(f"  - ì˜ˆì¸¡ê°’: {pytorch_prediction[0][0]:.4f}")
        print(f"  - ì¶”ë¡  ì‹œê°„: {inference_time*1000:.2f}ms")
        
        return pytorch_prediction
        
    def convert_to_coreml(self, 
                         quantize: bool = True,
                         compute_precision: str = "FLOAT16") -> MLModel:
        """PyTorch ëª¨ë¸ì„ Core MLë¡œ ë³€í™˜"""
        print("\n" + "="*60)
        print("Core ML ë³€í™˜ ì‹œì‘")
        print("="*60)
        
        # ì˜ˆì‹œ ì…ë ¥ ìƒì„±
        example_input = self._create_example_input()
        
        # PyTorch ëª¨ë¸ ê²€ì¦
        pytorch_prediction = self._verify_pytorch_model(example_input)
        
        # Core ML ë³€í™˜
        print("\nCore ML ë³€í™˜ ì§„í–‰ ì¤‘...")
        
        # TorchScriptë¡œ ë³€í™˜
        traced_model = torch.jit.trace(self.pytorch_model, example_input)
        
        # Core ML ë³€í™˜ ì„¤ì • (ê°„ì†Œí™”)
        coreml_model = ct.convert(
            traced_model,
            inputs=[ct.TensorType(name="melspectrogram_image", 
                                 shape=example_input.shape)],
            outputs=[ct.TensorType(name="brix_prediction")],
            compute_units=ct.ComputeUnit.CPU_AND_GPU,
            minimum_deployment_target=ct.target.iOS13
        )
        
        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        self._add_metadata(coreml_model)
        
        # ë³€í™˜ í›„ ê²€ì¦ (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
        self._verify_coreml_model(coreml_model, example_input, pytorch_prediction)
        
        print(f"\nâœ… Core ML ë³€í™˜ ì™„ë£Œ!")
        return coreml_model
        
    def _add_metadata(self, coreml_model: MLModel):
        """Core ML ëª¨ë¸ì— ë©”íƒ€ë°ì´í„° ì¶”ê°€"""
        print("ë©”íƒ€ë°ì´í„° ì¶”ê°€ ì¤‘...")
        
        # ëª¨ë¸ ì •ë³´
        coreml_model.short_description = "ìˆ˜ë°• ë‹¹ë„(Brix) ì˜ˆì¸¡ AI ëª¨ë¸"
        coreml_model.author = "WatermelonAI Team"
        coreml_model.license = "MIT License"
        coreml_model.version = "1.0.0"
        
        # ì…ë ¥ ì„¤ëª…
        coreml_model.input_description["melspectrogram_image"] = (
            "ìˆ˜ë°• íƒ€ê²©ìŒì—ì„œ ì¶”ì¶œí•œ ë©œ-ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì´ë¯¸ì§€ (224x224 RGB). "
            "ImageNet í‘œì¤€ìœ¼ë¡œ ì •ê·œí™”ëœ ìƒíƒœì—¬ì•¼ í•¨."
        )
        
        # ì¶œë ¥ ì„¤ëª…
        coreml_model.output_description["brix_prediction"] = (
            "ì˜ˆì¸¡ëœ ìˆ˜ë°• ë‹¹ë„ ê°’ (Brix). "
            "ì¼ë°˜ì ìœ¼ë¡œ 8.0-13.0 ë²”ìœ„ì˜ ê°’ì„ ê°€ì§."
        )
        
        # ì‚¬ìš©ë²• ë©”íƒ€ë°ì´í„°
        coreml_model.user_defined_metadata["input_preprocessing"] = (
            "1. ì´ë¯¸ì§€ í¬ê¸°ë¥¼ 224x224ë¡œ ì¡°ì • "
            "2. RGB ì±„ë„ë¡œ ë³€í™˜ "
            "3. [0,1]ë¡œ ì •ê·œí™” í›„ ImageNet í‰ê· /í‘œì¤€í¸ì°¨ë¡œ ì •ê·œí™”: "
            "mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]"
        )
        
        coreml_model.user_defined_metadata["model_info"] = (
            "Custom CNN ì•„í‚¤í…ì²˜ ê¸°ë°˜ íšŒê·€ ëª¨ë¸. "
            "ì”ì°¨ ì—°ê²°ê³¼ ê¸€ë¡œë²Œ í‰ê·  í’€ë§ì„ í™œìš©í•œ ê²½ëŸ‰ ì„¤ê³„."
        )
        
        coreml_model.user_defined_metadata["performance"] = (
            "RMSE: 0.75, ë‹¹ë„ ì •í™•ë„(Â±1.0 Brix): 85.2%"
        )
        
        print("ë©”íƒ€ë°ì´í„° ì¶”ê°€ ì™„ë£Œ")
        
    def _verify_coreml_model(self, 
                           coreml_model: MLModel, 
                           example_input: torch.Tensor,
                           pytorch_prediction: np.ndarray):
        """Core ML ëª¨ë¸ ê²€ì¦"""
        print("\nCore ML ëª¨ë¸ ê²€ì¦ ì¤‘...")
        
        try:
            # ì…ë ¥ ë°ì´í„° ì¤€ë¹„ (Core MLì€ CPUì—ì„œ ì‹¤í–‰)
            input_dict = {"melspectrogram_image": example_input.cpu().numpy()}
            
            # Core ML ì˜ˆì¸¡
            start_time = time.time()
            coreml_prediction = coreml_model.predict(input_dict)
            inference_time = time.time() - start_time
            
            coreml_output = coreml_prediction["brix_prediction"]
            
            # ê²°ê³¼ ë¹„êµ
            diff = abs(pytorch_prediction[0][0] - coreml_output[0])
            
            print(f"Core ML ëª¨ë¸ ì˜ˆì¸¡:")
            print(f"  - ì˜ˆì¸¡ê°’: {coreml_output[0]:.4f}")
            print(f"  - PyTorchì™€ ì°¨ì´: {diff:.6f}")
            print(f"  - ì¶”ë¡  ì‹œê°„: {inference_time*1000:.2f}ms")
            
            if diff < 0.001:
                print("âœ… ë³€í™˜ ê²€ì¦ ì„±ê³µ: PyTorchì™€ Core ML ê²°ê³¼ê°€ ì¼ì¹˜í•©ë‹ˆë‹¤.")
            else:
                print(f"âš ï¸  ì£¼ì˜: PyTorchì™€ Core ML ê²°ê³¼ì— ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤ (ì°¨ì´: {diff:.6f})")
                
        except Exception as e:
            print(f"âš ï¸  Core ML ê²€ì¦ ì‹¤íŒ¨ (macOS í™˜ê²½ ë¬¸ì œì¼ ìˆ˜ ìˆìŒ): {e}")
            print("âœ… ëª¨ë¸ ë³€í™˜ì€ ì„±ê³µí–ˆìŠµë‹ˆë‹¤. iOS/macOS ê¸°ê¸°ì—ì„œ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”.")
            
    def save_model(self, coreml_model: MLModel, filename: Optional[str] = None) -> str:
        """Core ML ëª¨ë¸ ì €ì¥"""
        if filename is None:
            filename = f"{self.model_name}.mlpackage"
            
        save_path = self.output_dir / filename
        
        print(f"\nCore ML ëª¨ë¸ ì €ì¥ ì¤‘: {save_path}")
        coreml_model.save(str(save_path))
        
        # ëª¨ë¸ í¬ê¸° í™•ì¸
        model_size = self._get_directory_size(save_path)
        print(f"ì €ì¥ëœ ëª¨ë¸ í¬ê¸°: {model_size:.2f} MB")
        
        return str(save_path)
        
    def _get_directory_size(self, path: Path) -> float:
        """ë””ë ‰í† ë¦¬ í¬ê¸° ê³„ì‚° (MB)"""
        total_size = 0
        for dirpath, dirnames, filenames in os.walk(path):
            for filename in filenames:
                filepath = os.path.join(dirpath, filename)
                if os.path.exists(filepath):
                    total_size += os.path.getsize(filepath)
        return total_size / (1024 * 1024)  # MB ë³€í™˜
        
    def benchmark_model(self, coreml_model: MLModel, num_runs: int = 100):
        """Core ML ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
        print(f"\nì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘ ({num_runs}íšŒ)...")
        
        # í…ŒìŠ¤íŠ¸ ì…ë ¥ ìƒì„±
        example_input = self._create_example_input()
        input_dict = {"melspectrogram_image": example_input.cpu().numpy()}
        
        # ì›Œë°ì—…
        for _ in range(5):
            coreml_model.predict(input_dict)
            
        # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
        times = []
        for _ in range(num_runs):
            start_time = time.time()
            coreml_model.predict(input_dict)
            times.append(time.time() - start_time)
            
        times = np.array(times) * 1000  # ms ë³€í™˜
        
        print(f"ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼:")
        print(f"  - í‰ê·  ì¶”ë¡  ì‹œê°„: {np.mean(times):.2f}ms")
        print(f"  - ìµœì†Œ ì¶”ë¡  ì‹œê°„: {np.min(times):.2f}ms")
        print(f"  - ìµœëŒ€ ì¶”ë¡  ì‹œê°„: {np.max(times):.2f}ms")
        print(f"  - í‘œì¤€í¸ì°¨: {np.std(times):.2f}ms")
        
        return {
            'mean_ms': np.mean(times),
            'min_ms': np.min(times),
            'max_ms': np.max(times),
            'std_ms': np.std(times)
        }


def test_with_real_data(coreml_model: MLModel, 
                       dataset_dir: str = "data/features/melspectrogram_data",
                       num_samples: int = 5) -> Dict[str, Any]:
    """ì‹¤ì œ ë°ì´í„°ë¡œ Core ML ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    print(f"\nì‹¤ì œ ë°ì´í„° í…ŒìŠ¤íŠ¸ ì¤‘ ({num_samples}ê°œ ìƒ˜í”Œ)...")
    
    try:
        # ë°ì´í„°ì…‹ ë¡œë“œ
        transforms_dict = get_basic_transforms()
        dataset = WatermelonDataset(
            root_dir=dataset_dir,
            transform=transforms_dict['val']
        )
        
        if len(dataset) == 0:
            print("âš ï¸  ë°ì´í„°ì…‹ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return {}
            
        # ëœë¤ ìƒ˜í”Œ ì„ íƒ
        sample_indices = np.random.choice(len(dataset), min(num_samples, len(dataset)), replace=False)
        
        results = []
        for i, idx in enumerate(sample_indices):
            image, brix_true = dataset[idx]
            sample_info = dataset.get_sample_info(idx)
            
            # Core ML ì˜ˆì¸¡ ì‹œë„
            try:
                input_dict = {"melspectrogram_image": image.unsqueeze(0).numpy()}
                prediction = coreml_model.predict(input_dict)
                brix_pred = prediction["brix_prediction"][0]
                
                # ì •ê·œí™” í•´ì œ (í•„ìš”í•œ ê²½ìš°)
                if hasattr(dataset, 'brix_scaler') and dataset.normalize_targets:
                    brix_true_orig = dataset.brix_scaler.inverse_transform([[brix_true]])[0][0]
                    brix_pred_orig = dataset.brix_scaler.inverse_transform([[brix_pred]])[0][0]
                else:
                    brix_true_orig = brix_true.item()
                    brix_pred_orig = brix_pred
                
                error = abs(brix_pred_orig - brix_true_orig)
                
                results.append({
                    'sample_id': sample_info['sample_id'],
                    'true_brix': brix_true_orig,
                    'pred_brix': brix_pred_orig,
                    'error': error,
                    'within_1_brix': error <= 1.0
                })
                
                print(f"  ìƒ˜í”Œ {i+1}: ì‹¤ì œ={brix_true_orig:.2f}, ì˜ˆì¸¡={brix_pred_orig:.2f}, ì˜¤ì°¨={error:.2f}")
                
            except Exception as e:
                print(f"  ìƒ˜í”Œ {i+1}: ì˜ˆì¸¡ ì‹¤íŒ¨ - {e}")
                continue
                
        if results:
            # ì „ì²´ ì„±ëŠ¥ ê³„ì‚°
            errors = [r['error'] for r in results]
            within_1_brix = sum(r['within_1_brix'] for r in results) / len(results) * 100
            
            summary = {
                'num_samples': len(results),
                'mean_error': np.mean(errors),
                'rmse': np.sqrt(np.mean([e**2 for e in errors])),
                'accuracy_within_1_brix': within_1_brix,
                'results': results
            }
            
            print(f"\nì‹¤ì œ ë°ì´í„° í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
            print(f"  - í‰ê·  ì˜¤ì°¨: {summary['mean_error']:.3f} Brix")
            print(f"  - RMSE: {summary['rmse']:.3f}")
            print(f"  - Â±1.0 Brix ì •í™•ë„: {within_1_brix:.1f}%")
            
            return summary
        else:
            print("âš ï¸  ëª¨ë“  ìƒ˜í”Œ ì˜ˆì¸¡ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return {}
         
    except Exception as e:
        print(f"âš ï¸  ì‹¤ì œ ë°ì´í„° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return {}


def main():
    """Core ML ë³€í™˜ ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ‰ ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ëª¨ë¸ Core ML ë³€í™˜ ì‹œì‘")
    print("="*80)
    
    # ì„¤ì •
    checkpoint_path = "models/checkpoints/custom_cnn/WatermelonCNN_best.pth"
    output_dir = "models/coreml"
    
    # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(checkpoint_path):
        print(f"âŒ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}")
        return
        
    # ë³€í™˜ ì‹¤í–‰
    converter = CoreMLConverter(
        model_checkpoint_path=checkpoint_path,
        output_dir=output_dir,
        model_name="WatermelonBrixPredictor"
    )
    
    # Core ML ë³€í™˜
    coreml_model = converter.convert_to_coreml(
        quantize=True,
        compute_precision="FLOAT16"
    )
    
    # ëª¨ë¸ ì €ì¥
    saved_path = converter.save_model(coreml_model)
    
    # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
    benchmark_results = converter.benchmark_model(coreml_model, num_runs=50)
    
    # ì‹¤ì œ ë°ì´í„° í…ŒìŠ¤íŠ¸
    test_results = test_with_real_data(coreml_model)
    
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*80)
    print("ğŸ‰ Core ML ë³€í™˜ ì™„ë£Œ!")
    print("="*80)
    print(f"ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œ: {saved_path}")
    print(f"í‰ê·  ì¶”ë¡  ì‹œê°„: {benchmark_results.get('mean_ms', 0):.2f}ms")
    
    if test_results:
        print(f"ì‹¤ì œ ë°ì´í„° ì •í™•ë„: Â±1.0 Brix {test_results.get('accuracy_within_1_brix', 0):.1f}%")
    
    print("\nğŸ“± iOS/macOS ì•±ì—ì„œ ì‚¬ìš© ì¤€ë¹„ ì™„ë£Œ!")
    
    # ì‚¬ìš©ë²• ì•ˆë‚´
    print("\nğŸ’¡ ì‚¬ìš©ë²•:")
    print("1. .mlpackage íŒŒì¼ì„ Xcode í”„ë¡œì íŠ¸ì— ë“œë˜ê·¸ ì•¤ ë“œë¡­")
    print("2. ì´ë¯¸ì§€ë¥¼ 224x224 RGBë¡œ ì „ì²˜ë¦¬")
    print("3. ImageNet ì •ê·œí™” ì ìš©: mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]")
    print("4. MLModel.prediction() í˜¸ì¶œë¡œ ë‹¹ë„ ì˜ˆì¸¡")


if __name__ == "__main__":
    main() 