#!/usr/bin/env python3
"""
ìˆ˜ë°• ë‹¹ë„ íŒë³„ í”„ë¡œì íŠ¸ - ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
Audio Preprocessing Pipeline for Watermelon Brix Detection Project
"""

import os
import numpy as np
import librosa
import soundfile as sf
from pathlib import Path
from scipy import signal
from typing import Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

class AudioPreprocessor:
    def __init__(self, 
                 target_sr: int = 22050,
                 target_duration: float = 3.0,
                 normalize: bool = True,
                 apply_noise_reduction: bool = True):
        """
        ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        
        Args:
            target_sr: ëª©í‘œ ìƒ˜í”Œë§ ë ˆì´íŠ¸ (Hz)
            target_duration: ëª©í‘œ ê¸¸ì´ (ì´ˆ)
            normalize: ì •ê·œí™” ì ìš© ì—¬ë¶€
            apply_noise_reduction: ë…¸ì´ì¦ˆ ì œê±° ì ìš© ì—¬ë¶€
        """
        self.target_sr = target_sr
        self.target_duration = target_duration
        self.target_length = int(target_sr * target_duration)
        self.normalize = normalize
        self.apply_noise_reduction = apply_noise_reduction
        
    def load_audio(self, file_path: Path) -> Tuple[np.ndarray, int]:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.
        
        Args:
            file_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Tuple[ì˜¤ë””ì˜¤ ì‹ í˜¸, ìƒ˜í”Œë§ ë ˆì´íŠ¸]
        """
        try:
            # Path ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            audio_signal, sample_rate = librosa.load(str(file_path), sr=self.target_sr)
            return audio_signal, sample_rate
        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ë¡œë“œ ì‹¤íŒ¨ ({file_path.name}): {e}")
            return None, None
    
    def remove_noise(self, audio: np.ndarray, sr: int) -> np.ndarray:
        """
        ìŠ¤í™íŠ¸ëŸ´ ì„œë¸ŒíŠ¸ë™ì…˜ì„ ì´ìš©í•œ ë…¸ì´ì¦ˆ ì œê±°
        
        Args:
            audio: ì…ë ¥ ì˜¤ë””ì˜¤ ì‹ í˜¸
            sr: ìƒ˜í”Œë§ ë ˆì´íŠ¸
            
        Returns:
            ë…¸ì´ì¦ˆê°€ ì œê±°ëœ ì˜¤ë””ì˜¤ ì‹ í˜¸
        """
        # ì§§ì€ ì‹œê°„ í‘¸ë¦¬ì— ë³€í™˜
        stft = librosa.stft(audio)
        magnitude = np.abs(stft)
        phase = np.angle(stft)
        
        # ë…¸ì´ì¦ˆ ì¶”ì • (ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ í”„ë ˆì„ë“¤ì˜ í‰ê· )
        noise_frames = 5
        noise_magnitude = np.mean(magnitude[:, :noise_frames], axis=1, keepdims=True)
        
        # ìŠ¤í™íŠ¸ëŸ´ ì„œë¸ŒíŠ¸ë™ì…˜
        alpha = 2.0  # ê³¼ì†Œ ì œê±° ê³„ìˆ˜
        beta = 0.01  # ì”ì—¬ ë…¸ì´ì¦ˆ í”Œë¡œì–´
        
        cleaned_magnitude = magnitude - alpha * noise_magnitude
        cleaned_magnitude = np.maximum(cleaned_magnitude, beta * magnitude)
        
        # ì—­ë³€í™˜
        cleaned_stft = cleaned_magnitude * np.exp(1j * phase)
        cleaned_audio = librosa.istft(cleaned_stft)
        
        return cleaned_audio
    
    def normalize_audio(self, audio: np.ndarray) -> np.ndarray:
        """
        ì˜¤ë””ì˜¤ ì‹ í˜¸ë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤.
        
        Args:
            audio: ì…ë ¥ ì˜¤ë””ì˜¤ ì‹ í˜¸
            
        Returns:
            ì •ê·œí™”ëœ ì˜¤ë””ì˜¤ ì‹ í˜¸
        """
        # RMS ê¸°ë°˜ ì •ê·œí™”
        rms = np.sqrt(np.mean(audio**2))
        if rms > 0:
            target_rms = 0.1  # ëª©í‘œ RMS ê°’
            audio = audio * (target_rms / rms)
        
        # í´ë¦¬í•‘ ë°©ì§€
        audio = np.clip(audio, -1.0, 1.0)
        
        return audio
    
    def adjust_length(self, audio: np.ndarray) -> np.ndarray:
        """
        ì˜¤ë””ì˜¤ ê¸¸ì´ë¥¼ ëª©í‘œ ê¸¸ì´ë¡œ ì¡°ì •í•©ë‹ˆë‹¤.
        
        Args:
            audio: ì…ë ¥ ì˜¤ë””ì˜¤ ì‹ í˜¸
            
        Returns:
            ê¸¸ì´ ì¡°ì •ëœ ì˜¤ë””ì˜¤ ì‹ í˜¸
        """
        current_length = len(audio)
        
        if current_length > self.target_length:
            # ì¤‘ì•™ ë¶€ë¶„ ì¶”ì¶œ
            start_idx = (current_length - self.target_length) // 2
            audio = audio[start_idx:start_idx + self.target_length]
        elif current_length < self.target_length:
            # ì œë¡œ íŒ¨ë”©
            padding = self.target_length - current_length
            pad_left = padding // 2
            pad_right = padding - pad_left
            audio = np.pad(audio, (pad_left, pad_right), mode='constant')
        
        return audio
    
    def apply_bandpass_filter(self, audio: np.ndarray, sr: int) -> np.ndarray:
        """
        ìˆ˜ë°• íƒ€ê²©ìŒì— ì í•©í•œ ëŒ€ì—­í†µê³¼ í•„í„°ë¥¼ ì ìš©í•©ë‹ˆë‹¤.
        
        Args:
            audio: ì…ë ¥ ì˜¤ë””ì˜¤ ì‹ í˜¸
            sr: ìƒ˜í”Œë§ ë ˆì´íŠ¸
            
        Returns:
            í•„í„°ë§ëœ ì˜¤ë””ì˜¤ ì‹ í˜¸
        """
        # ìˆ˜ë°• íƒ€ê²©ìŒì˜ ì£¼ìš” ì£¼íŒŒìˆ˜ ëŒ€ì—­: 100Hz ~ 4000Hz
        lowcut = 100.0
        highcut = 4000.0
        
        # ë²„í„°ì›ŒìŠ¤ í•„í„° ì„¤ê³„
        nyquist = sr / 2
        low = lowcut / nyquist
        high = highcut / nyquist
        
        b, a = signal.butter(4, [low, high], btype='band')
        filtered_audio = signal.filtfilt(b, a, audio)
        
        return filtered_audio
    
    def preprocess_audio(self, file_path: Path, save_path: Optional[Path] = None) -> Optional[np.ndarray]:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            file_path: ì…ë ¥ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            save_path: ì „ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ì €ì¥ ê²½ë¡œ (ì„ íƒì‚¬í•­)
            
        Returns:
            ì „ì²˜ë¦¬ëœ ì˜¤ë””ì˜¤ ì‹ í˜¸ (ì‹¤íŒ¨ì‹œ None)
        """
        # 1. ì˜¤ë””ì˜¤ ë¡œë“œ
        audio, sr = self.load_audio(file_path)
        if audio is None:
            return None
        
        print(f"ğŸ“ ì²˜ë¦¬ ì¤‘: {file_path.name} (ê¸¸ì´: {len(audio)/sr:.2f}ì´ˆ, SR: {sr}Hz)")
        
        # 2. ëŒ€ì—­í†µê³¼ í•„í„° ì ìš©
        audio = self.apply_bandpass_filter(audio, sr)
        
        # 3. ë…¸ì´ì¦ˆ ì œê±°
        if self.apply_noise_reduction:
            audio = self.remove_noise(audio, sr)
        
        # 4. ì •ê·œí™”
        if self.normalize:
            audio = self.normalize_audio(audio)
        
        # 5. ê¸¸ì´ ì¡°ì •
        audio = self.adjust_length(audio)
        
        # 6. ì €ì¥ (ì„ íƒì‚¬í•­)
        if save_path:
            save_path.parent.mkdir(parents=True, exist_ok=True)
            sf.write(str(save_path), audio, sr)
            print(f"ğŸ’¾ ì €ì¥ë¨: {save_path}")
        
        print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: ìµœì¢… ê¸¸ì´ {len(audio)/sr:.2f}ì´ˆ")
        return audio
    
    def process_dataset(self, data_root: Path, output_root: Path):
        """
        ì „ì²´ ë°ì´í„°ì…‹ì„ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            data_root: ì›ë³¸ ë°ì´í„° ë£¨íŠ¸ ê²½ë¡œ
            output_root: ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ê²½ë¡œ
        """
        print("ğŸ”„ ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ ì‹œì‘...")
        output_root.mkdir(parents=True, exist_ok=True)
        
        # ëª¨ë“  ìˆ˜ë°• í´ë” ì°¾ê¸°
        watermelon_folders = sorted([f for f in data_root.iterdir() 
                                   if f.is_dir() and '_' in f.name])
        
        processed_count = 0
        failed_count = 0
        
        for folder in watermelon_folders:
            folder_name = folder.name
            print(f"\nğŸ“‚ í´ë” ì²˜ë¦¬ ì¤‘: {folder_name}")
            
            # ì¶œë ¥ í´ë” ìƒì„±
            output_folder = output_root / folder_name
            output_folder.mkdir(exist_ok=True)
            
            # audio í´ë”ì˜ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬
            audio_folder = folder / 'audio'
            if audio_folder.exists():
                audio_files = [f for f in audio_folder.iterdir() if f.is_file()]
                
                for audio_file in audio_files:
                    # ì¶œë ¥ íŒŒì¼ëª… (ëª¨ë‘ wavë¡œ í†µì¼)
                    output_file = output_folder / f"{audio_file.stem}_processed.wav"
                    
                    # ì „ì²˜ë¦¬ ìˆ˜í–‰
                    processed_audio = self.preprocess_audio(audio_file, output_file)
                    
                    if processed_audio is not None:
                        processed_count += 1
                    else:
                        failed_count += 1
        
        print(f"\nğŸ‰ ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"âœ… ì„±ê³µ: {processed_count}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {failed_count}ê°œ")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_root}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸµ ìˆ˜ë°• ë‹¹ë„ íŒë³„ í”„ë¡œì íŠ¸ - ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬")
    print("="*60)
    
    # ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
    preprocessor = AudioPreprocessor(
        target_sr=22050,        # 22.05kHz
        target_duration=3.0,    # 3ì´ˆ
        normalize=True,
        apply_noise_reduction=True
    )
    
    # ê²½ë¡œ ì„¤ì •
    data_root = Path("watermelon_data")
    output_root = Path("preprocessed_data")
    
    # ë°ì´í„°ì…‹ ì „ì²˜ë¦¬
    if data_root.exists():
        preprocessor.process_dataset(data_root, output_root)
    else:
        print(f"âŒ ë°ì´í„° í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_root}")
    
    # ìƒ˜í”Œ ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    print("\nğŸ“‹ ìƒ˜í”Œ ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸...")
    sample_folder = data_root / "01_10.5" / "audio"
    if sample_folder.exists():
        sample_files = list(sample_folder.glob("*"))[:2]  # ì²« 2ê°œ íŒŒì¼ë§Œ
        
        for sample_file in sample_files:
            print(f"\nğŸ”§ í…ŒìŠ¤íŠ¸: {sample_file.name}")
            processed_audio = preprocessor.preprocess_audio(sample_file)
            if processed_audio is not None:
                print(f"   ê²°ê³¼: ê¸¸ì´ {len(processed_audio)} ìƒ˜í”Œ, RMS {np.sqrt(np.mean(processed_audio**2)):.4f}")

if __name__ == "__main__":
    main() 